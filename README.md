<div align="center">
    <img src="assets/nvwa.png" height="90" alt="Logo">
    <h3 style="font-size: 50pt;" align=center><strong>NÃ¼wa</strong></h2>
  </a>
</div>

<div align=center>
<h2 style="font-size: 50pt;" align=center><strong>Towards Large Language Model to Be a Traditional Chinese Medicine Doctor</strong></h2>
</div>

### ğŸ“– Introduction
we introduce NÃ¼wa, a comprehensive Traditional Chinese Medicine LLM that encompasses the entire training pipeline from Continuous Pre-training and Supervised Instruction Fine-tuning to Reinforcement Learning from AI Feedback. Nuwa outperforms other open-source Chinese medical LLMs within TCM domain, thanks in part to our construction of a large-scale TCM training corpus and TCM dialogue dataset.

<div align="center">
<img src="assets/flowchart.png" width="100%" height="100%">
</div>

### ğŸ”¥ News and Updates

âœ… [2024/08/15] NÃ¼wa starts releasing dataset, code, etc.

âœ… [2024/08/01] NÃ¼wa TCM repo is created.

### ğŸ“š Data

- `data/pretrain`: Contains part of TCM corpus for continuous pre-training the model.

- `data/finetune`: Contains part of TCM-QR for supervised instruction fine-tuning the model.

- `data/reward`: Contains samples for training the reward model.

### â­ Code Structure

### âš™ï¸ Getting Started

### ğŸŒ Quick Start





